%!TEX root = ../thesis.tex
%*******************************************************************************
%*********************************** Statistics *********
%*******************************************************************************


\chapter{Statistical data analysis}\label{ch:statistics}

\ifpdf
    \graphicspath{{chapter-statistics/Figs/Raster/}{chapter-statistics/Figs/PDF/}{chapter-statistics/Figs/}}
\else
    \graphicspath{{chapter-statistics/Figs/Vector/}{chapter-statistics/Figs/}}
\fi

\glsreset{pdf}

Statistical models are used in order to order to quantify the correspondence between theoretical predictions and the experimental observations in searches for \gls{bsm} physics. This chapter introduces the statistical concepts, methods and formulae used in this work for statistical inference. A frequentist approach to statistics is employed, interpreting probabilities as the frequencies of the outcomes of repeatable experiments that may either be real, based on computer simulations, or mathematical abstraction~\cite{pdg2020,Cranmer:2015nia}. The ensuing description largely follows~\cite{Cranmer:2015nia, Cowan:2010js}

\section{The likelihood function}
 
In measurements in high energy physics, a \textit{statistical model} $f(\boldsymbol{x}\vert\boldsymbol{\phi})$ is a parametric family of \glspl{pdf} describing the probability of observing data $\boldsymbol{x}$ given a set of model parameters $\phi$ that typically describe parameters of the physical theory or unknown detector effects. The \textit{likelihood function} $L(\boldsymbol{\phi})$ is then numerically equivalent to $f(\boldsymbol{x}\vert\boldsymbol{\phi})$ with $\boldsymbol{x}$ fixed. As opposed to the \gls{pdf} $f(\boldsymbol{x})$ which describes the value of $f$ as a function of $\boldsymbol{x}$ given a fixed set of parameters $\boldsymbol{\phi}$, the likelihood refers to the value of $f$ as a function of $\boldsymbol{\phi}$ given a fixed value of $\boldsymbol{x}$.

Searches for \gls{bsm} physics are typically centred around the measurement of several disjoint binned distributions (called \textit{channels} $c$) that are each associated with different event selection criteria (as opposed to different scattering processes) yielding observed event counts $\boldsymbol{n}$. In such counting experiments where each event is independently drawn from the same underlying distribution, each bin is fundamentally described by a Poisson term. The Poisson probability to observe $n$ events with a expectation of $\nu$ events, is given by
\begin{equation}
	\mathrm{Pois}(n\vert\nu) = \frac{\nu^n}{n!}e^{-\nu}.
\end{equation}
The expectation $\nu_{cb}$ in each channel $c$ and bin $b$ is a sum over the set of physics processes considered (called \textit{samples}). The sample-wise rates are in general a function of the the model parameters $\boldsymbol{\phi}$, that can either be \textit{free parameters} $\boldsymbol{\eta}$ or \textit{constrained parameters} $\boldsymbol{\chi}$. Free parameters directly determined by the Poisson terms for the data observations are called \textit{normalisation factors} $\boldsymbol{\mu}$. The constrained parameters represent the systematic uncertainties considered in the model. The degree to which they cause a deviation of the expected event rates from the nominal event rates is limited through \textit{constraint terms} $c_{\boldsymbol{\chi}}(a_{\boldsymbol{\chi}}\vert\boldsymbol{\chi})$ that can be viewed as \textit{auxiliary measurements} with global observed data $\boldsymbol{a}$. 

For a given observation $\boldsymbol{x} = (\boldsymbol{n},\boldsymbol{a})$ of observed events $\boldsymbol{n}$ and auxiliary data $\boldsymbol{a}$, the likelihood then reads
\begin{equation}
	L (\boldsymbol{\eta}, \boldsymbol{\chi}) = \prod_{c\in\mathrm{channels}} \prod_{b\in\mathrm{bins_c}} \mathrm{Pois}(n_{cb}\vert\nu_{cb}(\boldsymbol{\eta},\boldsymbol{\chi})) \prod_{\chi\in\boldsymbol{\chi}}c_\chi (a_\chi\vert\chi),
\end{equation}
where, given a certain integrated luminosity, $n_{cb}$ and $\nu_{cb}$ refer to the corresponding observed and expected rate of events, respectively~\cite{ATL-PHYS-PUB-2019-029}. Most of the systematic uncertainties are so-called \textit{interpolation parameters} $\boldsymbol{\alpha}$ representing either normalisation uncertainties or correlated shape uncertainties\improvement{Explain this further}. Their constraint terms $c_{\boldsymbol{\alpha}}(a_{\boldsymbol{\alpha}}\vert\boldsymbol{\alpha})$ are parametrised by a Gaussian with mean $a = 0\vert\alpha$ and variance $\sigma = 1$, with $\alpha = 0$ representing the nominal value. The \textit{up} and \textit{down} variations are then given by $\alpha=\pm 1$, thus representing $\pm 1\sigma$ variations. The impact of any given value of the parameter on the event rates is then evaluated through polynomial interpolation and exponential extrapolation, a method that avoids discontinuous first and second derivatives at $\alpha = 0$ and ensures positive values for the predicted event rates.

Sample rates derived from theory calculations (\ie \gls{mc} simulation), are scaled to the integrated luminosity corresponding to the observed data. The integrated luminosity is itself a measurement that is subject to uncertainties. Therefore, an additional constraint term in the likelihood is needed. It is parametrised by a Gaussian with mean corresponding to the nominal integrated luminosity measurement and variance equal to the integrated luminosity measurement uncertainty.

Uncertainties arising from the finite size of the \gls{mc} datasets often used to derive estimated event rates are modelled by bin-wise scale factors $\gamma_b$. The constraint terms are Gaussian distributions with central value equal to unity and variances calculated from the individual uncertainties of the samples defined in the respective channel.

As the event rate in a given bin can depend on multiple parameters, and, likewise, a single parameter can affect the expected event rate in multiple bins, correlations between the model parameters $\boldsymbol{\phi}$ can occur.

The above prescription for building statistical models is called the \textsc{HistFactory} template~\cite{Cranmer:1456844}. In this work, two independent implementation of the \textsc{HistFactory} template are used. One implementation uses \textsc{RooFit} and \textsc{RooStats}

 
%\begin{equation}
%	\nu_{cb}(\boldsymbol{\phi}) = \sum_{s\in\mathrm{samples}}{}\nu_{scb}(\boldsymbol{\phi}) = \sum_{s\in\mathrm{samples}}{\left(\prod_{\kappa\in\boldsymbol{\kappa}}\kappa_{scb}(\boldsymbol{\phi})\right)\left(\nu^0_{scb}(\boldsymbol{\phi})+\sum_{\Delta\in\boldsymbol{\Delta}}\Delta_{scb}(\boldsymbol{\phi})\right)},
%\end{equation} 
%where $\nu_{scb}$ are sample-wise event rates determined from \textit{nominal rates} $\nu^0_{scb}$ and a set of multiplicative and additive \textit{rate modifiers} $\boldsymbol{\kappa(\phi)}$ and $\boldsymbol{\Delta(\phi)}$, that are functions of the model parameters (typically only a single parameter per modifier). The modifiers are paired with a constraint term in order to implement systematic uncertainties into the statistical model. The event rates in a given bin can be affected by multiple parameters and single parameters can 

 The full model parameter set is typically separated into \textit{parameters of interest} $\boldsymbol{\psi}$ and \textit{nuisance parameters} $\boldsymbol{\theta}$ that are not of immediate interest but need to be accounted for in the statistical model. In the search presented in this work, the only \gls{poi} is the \textit{signal strength} parameter $\mu_{\mathrm{sig}}$, representing the ratio of the signal process cross section to its reference cross section as expected from theory.


The expectation $\nu_i$ in each bin $i$ can be parametrised through the introduction of a signal strength parameter $\mu_{\mathrm{sig}}$ by
\begin{equation}
	\nu_i = \mu_{\mathrm{sig}}s_i + b_i,
\end{equation}
where $s_i$ and $b_i$ are the bin-wise expected signal and background rates, respectively. The signal strength $\mu_{\mathrm{sig}}$ and is used as \gls{poi} in fits to data. Fixing $\mu_{\mathrm{sig}} = 0$ yields a \gls{sm} expectation, while $\mu_{\mathrm{sig}} = 1$ represents a \textit{signal-plus-background} description at nominal signal cross section. Scanning multiple values of $\mu_{\mathrm{sig}}$ allows to set limits on the visible cross sections of the signal models considered in the search. 
  
For each of the channels, the total event rate is the sum over a set of physics processes, called \textit{samples}. The sample-wise event rates are in general a function of the the model parameters $\boldsymbol{\phi}$




\section{Parameter estimation}

\section{Statistical tests}